{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: predict the property's price\n",
    "\n",
    "**(1) Data Understanding**\n",
    "\n",
    "**(2) Data Transformation and Formatting -- ETL pipeline**\n",
    "\n",
    "**(3) ML Data Preperation - extract features and obtain train and validate data**\n",
    "- **Check for missing values**:\n",
    "\n",
    "- **Missing value imputation**\n",
    "    - Missing values imputations using `\"continuous_imputation()\"` function\n",
    "\n",
    "- **Handle categorical variables**:\n",
    "    - Encoding categorical variable, \"amenities\" from the listings data using `\"encode_amenities()\"` function\n",
    "    - Encoding other categorical variables, using one-hot encoding or target encoding using `\"category_encoding\"` function\n",
    "    \n",
    "- **Finally, we can use `\"ml_dataprep()\"` for ml_dataprep**.\n",
    "\n",
    "**(4) Data Modeling and Evaluate the Results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# statistics\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math as mt\n",
    "\n",
    "# Data Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "# Data Preprocessing - Standardization, Encoding, Imputation\n",
    "from sklearn.preprocessing import StandardScaler # Standardization\n",
    "from sklearn.preprocessing import Normalizer # Normalization\n",
    "from sklearn.preprocessing import OneHotEncoder # One-hot Encoding\n",
    "from sklearn.preprocessing import OrdinalEncoder # Ordinal Encoding\n",
    "from category_encoders import MEstimateEncoder # Target Encoding\n",
    "from sklearn.preprocessing import PolynomialFeatures # Create Polynomial Features\n",
    "from sklearn.impute import SimpleImputer # Imputation\n",
    "\n",
    "# Exploratory Data Analysis - Feature Engineering\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Modeling - ML Pipelines\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Modeling - Algorithms\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "\n",
    "# ML - Evaluation\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import cross_val_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1) Data Understanding\n",
    "\n",
    "**Load dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/seattle-parks-and-recreation-park-addresses.csv\n",
      "../data/reviews.csv\n",
      "../data/tourist attractions_clean.csv\n",
      "../data/listings_cs_kfold.csv\n",
      "../data/listings.csv\n",
      "../data/listings_cs.csv\n",
      "../data/calendar.csv\n",
      "../data/seattle_top55 tourist attractions.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/home/chenj107/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3071: DtypeWarning: Columns (40) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "for dirname, _, filenames in os.walk(\"../data\"):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "        \n",
    "listings = pd.read_csv(\"../data/listings_cs.csv\") \n",
    "reviews = pd.read_csv(\"../data/reviews.csv\")\n",
    "calendar = pd.read_csv(\"../data/calendar.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we import three files included in the Seattle dataset:\n",
    "- *Listings*, including full descriptions and average review score.\n",
    "    - Note: This `\"listings_cs.csv\"` is not exactly the same file as the original data provided on Kaggle, but with some convenience_score_related features calculated from `\"convenience_score.ipynb\"`.\n",
    "    \n",
    "- *Reviews*, including unique id for each reviewer and detailed comments\n",
    "- *Calendar*, including listing id and the price and availability for that day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3818, 595), (1393570, 4), (84849, 6))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listings.shape, calendar.shape, reviews.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cross-Validation KFold**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/home/chenj107/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3263: DtypeWarning: Columns (40) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  if (await self.run_code(code, result,  async_=asy)):\n",
      "/mnt/home/chenj107/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3071: DtypeWarning: Columns (40) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>kfold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>241032</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>953595</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3308979</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7421966</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>278830</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  kfold\n",
       "0   241032    0.0\n",
       "1   953595    4.0\n",
       "2  3308979    2.0\n",
       "3  7421966    3.0\n",
       "4   278830    4.0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_listings_kfold():\n",
    "    # Mark the train dataset with kfold = 5\n",
    "    listings = pd.read_csv(\"../data/listings_cs.csv\")\n",
    "    \n",
    "    if os.path.exists(\"../data/listings_cs_kfold.csv\"):\n",
    "        os.remove(\"../data/listings_cs_kfold.csv\")\n",
    "    \n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    for fold, (train_idx, valid_idx) in enumerate(kf.split(X=listings)):\n",
    "        listings.loc[valid_idx, \"kfold\"] = fold\n",
    "\n",
    "    listings.to_csv('../data/listings_cs_kfold.csv', index=False)\n",
    "\n",
    "# After assigning kfold\n",
    "generate_listings_kfold()\n",
    "listings = pd.read_csv(\"../data/listings_cs_kfold.csv\")\n",
    "listings.loc[:, ['id', 'kfold']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) Data Transformation and Formatting -- ETL pipeline\n",
    "- Note: the \"ETL pipeline\" code is borrowed from Zacks Shen https://github.com/ZacksAmber/Kaggle-Seattle-Airbnb. \n",
    "\n",
    "His project conducted a price prediction model with the same dataset, but we have different research questions. This project is to investigate whether the convenience scores created by step 2 can benefit the price prediction outcomes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ETL_pipeline:\n",
    "    def __init__(self, data_frame):\n",
    "        self.df = data_frame\n",
    "    \n",
    "    # Data type transformation\n",
    "    def _transformation(self, data_frame):\n",
    "        df = data_frame\n",
    "        # Convert dollar columns from object to float\n",
    "        # Remove '$' and ','\n",
    "        dollar_cols = ['price', 'weekly_price', 'monthly_price', 'extra_people', 'security_deposit', 'cleaning_fee']\n",
    "        for dollar_col in dollar_cols:\n",
    "            df[dollar_col] = df[dollar_col].replace('[\\$,]', '', regex=True).astype(float)\n",
    "        \n",
    "        # Convert rate columns from object to float\n",
    "        # Remove '%'\n",
    "        percent_cols = ['host_response_rate', 'host_acceptance_rate']\n",
    "        for percent_col in percent_cols:\n",
    "            df[percent_col] = df[percent_col].replace('%', '', regex=True).astype(float)\n",
    "\n",
    "        # Replace the following values in \"property_type\" to Unique space due to small sample size\n",
    "        unique_space = [\"Barn\", \"Boat\",\"Bus\",\"Camper/RV\", \"Treehouse\",\"Campsite\",\"Castle\",\"Cave\", \"Dome House\",\n",
    "        \"Earth house\",\"Farm stay\",\"Holiday park\", \"Houseboat\", \"Hut\",\"Igloo\", \"Island\", \"Lighthouse\", \"Plane\",\n",
    "        \"Ranch\",  \"Religious building\",\"Shepherd’s hut\", \"Shipping container\", \"Tent\", \"Tiny house\", \"Tipi\",\n",
    "        \"Tower\", \"Train\",\"Windmill\", \"Yurt\",\"Riad\",\"Pension\",\"Dorm\", \"Chalet\"]            \n",
    "        df.property_type = df.property_type.replace(unique_space, \"Unique space\", regex=True)\n",
    "\n",
    "        # Convert 't'(true), 'f'(false) to 1, 0\n",
    "        tf_cols = ['host_is_superhost', 'instant_bookable', 'require_guest_profile_picture', 'require_guest_phone_verification']\n",
    "        for tf_col in tf_cols:\n",
    "            df[tf_col] = df[tf_col].replace('f', 0, regex=True)\n",
    "            df[tf_col] = df[tf_col].replace('t', 1, regex=True)\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    # Parse listings\n",
    "    def parse_listings(self):\n",
    "        \"\"\"Parse listings.\n",
    "        \"\"\"\n",
    "        df = self.df\n",
    "        df = self._transformation(df)\n",
    "        return df\n",
    "    \n",
    "    def parse_reviews(self):\n",
    "        \"\"\"Parse reviews.\n",
    "        \"\"\"\n",
    "        df = self.df\n",
    "        df.date = pd.to_datetime(df.date)\n",
    "        return df\n",
    "    \n",
    "    # Parse calendar\n",
    "    def parse_calender(self):\n",
    "        \"\"\"Paser calendar.\n",
    "        \"\"\"\n",
    "        df = self.df\n",
    "        # Convert date from object to datetime\n",
    "        df.date = pd.to_datetime(df.date)\n",
    "        \n",
    "        # Convert price from object to float\n",
    "        # Convert '$' and ',' to ''\n",
    "        df.price = df.price.replace('[\\$,]', '', regex=True).astype(float)\n",
    "        \n",
    "        # Convert 't', 'f' to 1, 0\n",
    "        df['available'] = df['available'].replace('f', 0, regex=True)\n",
    "        df['available'] = df['available'].replace('t', 1, regex=True)\n",
    "        return df\n",
    "\n",
    "listings = pd.read_csv(\"../data/listings_cs_kfold.csv\")\n",
    "listings = ETL_pipeline(listings).parse_listings()\n",
    "reviews = ETL_pipeline(reviews).parse_reviews()\n",
    "calendar = ETL_pipeline(calendar).parse_calender()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "listing_id\n",
       "3335    365\n",
       "4291    365\n",
       "5682    365\n",
       "6606    365\n",
       "7369    365\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The calendar recorded the availability of each listing in the next 365 days\n",
    "calendar.groupby('listing_id').size().head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (3) ML_dataprep pipeline\n",
    "\n",
    "- **Check for missing values**:\n",
    "\n",
    "- **Missing value imputation**\n",
    "    - Missing values imputations using `\"continuous_imputation()\"` function\n",
    "\n",
    "- **Handle categorical variables**:\n",
    "    - Encoding categorical variable, \"amenities\" from the listings data using `\"encode_amenities()\"` function\n",
    "    - Encoding other categorical variables, using one-hot encoding or target encoding using `\"category_encoding\"` function\n",
    "    \n",
    "- **Finally, we can use `\"ml_dataprep()\"` for ml_dataprep**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check for missing values**\n",
    "\n",
    "- Based on Zacks Shen's analysis, there are 3 types of features with missing values, including \"zero_features\" (will fill with 0), \"mean_features\"(will fill with col-mean) and \"mode_features\"(will fill with most-frequent value, can be used for categorical features such as 'property_type'). Let's firstly check the percentages of missing values for each selected features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The percentage of missing values for each column in the \"zero-feature set\"\n",
      " reviews_per_month     0.164\n",
      "host_response_rate    0.137\n",
      "host_is_superhost     0.001\n",
      "security_deposit      0.511\n",
      "cleaning_fee          0.270\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews_per_month</th>\n",
       "      <th>host_response_rate</th>\n",
       "      <th>host_is_superhost</th>\n",
       "      <th>security_deposit</th>\n",
       "      <th>cleaning_fee</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.07</td>\n",
       "      <td>96%</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.48</td>\n",
       "      <td>98%</td>\n",
       "      <td>t</td>\n",
       "      <td>$100.00</td>\n",
       "      <td>$40.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   reviews_per_month host_response_rate host_is_superhost security_deposit  \\\n",
       "0               4.07                96%                 f              NaN   \n",
       "1               1.48                98%                 t          $100.00   \n",
       "\n",
       "  cleaning_fee  \n",
       "0          NaN  \n",
       "1       $40.00  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Based on \"Zacks Shen\" analysis, there are 3 types of continous features with missing values, including \"\"\n",
    "zero_features = ['reviews_per_month', 'host_response_rate', 'host_is_superhost', 'security_deposit', 'cleaning_fee']\n",
    "mean_features = ['host_acceptance_rate', 'review_scores_accuracy', 'review_scores_checkin', \n",
    "                         'review_scores_value', 'review_scores_location', 'review_scores_cleanliness', \n",
    "                         'review_scores_communication', 'review_scores_rating']\n",
    "mode_features = ['bathrooms', 'bedrooms', 'beds', 'property_type']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the missing proportion for each set of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the \"zero-feature set\",\n",
      "\tthe percentage of missing values for each column is shown below\n",
      " reviews_per_month     0.164\n",
      "host_response_rate    0.137\n",
      "host_is_superhost     0.001\n",
      "security_deposit      0.511\n",
      "cleaning_fee          0.270\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews_per_month</th>\n",
       "      <th>host_response_rate</th>\n",
       "      <th>host_is_superhost</th>\n",
       "      <th>security_deposit</th>\n",
       "      <th>cleaning_fee</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.07</td>\n",
       "      <td>96%</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.48</td>\n",
       "      <td>98%</td>\n",
       "      <td>t</td>\n",
       "      <td>$100.00</td>\n",
       "      <td>$40.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   reviews_per_month host_response_rate host_is_superhost security_deposit  \\\n",
       "0               4.07                96%                 f              NaN   \n",
       "1               1.48                98%                 t          $100.00   \n",
       "\n",
       "  cleaning_fee  \n",
       "0          NaN  \n",
       "1       $40.00  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('For the \"zero-feature set\",\\n\\tthe percentage of missing values for each column is shown below\\n', round( \n",
    "    listings[zero_features].isnull().sum(axis = 0)/len(listings), 3))\n",
    "listings[zero_features].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the \"mean-feature set\",\n",
      "\tthe percentage of missing values for each column is shown below\n",
      " host_acceptance_rate           0.202\n",
      "review_scores_accuracy         0.172\n",
      "review_scores_checkin          0.172\n",
      "review_scores_value            0.172\n",
      "review_scores_location         0.172\n",
      "review_scores_cleanliness      0.171\n",
      "review_scores_communication    0.171\n",
      "review_scores_rating           0.169\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>host_acceptance_rate</th>\n",
       "      <th>review_scores_accuracy</th>\n",
       "      <th>review_scores_checkin</th>\n",
       "      <th>review_scores_value</th>\n",
       "      <th>review_scores_location</th>\n",
       "      <th>review_scores_cleanliness</th>\n",
       "      <th>review_scores_communication</th>\n",
       "      <th>review_scores_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100%</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>95.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100%</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>96.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  host_acceptance_rate  review_scores_accuracy  review_scores_checkin  \\\n",
       "0                 100%                    10.0                   10.0   \n",
       "1                 100%                    10.0                   10.0   \n",
       "\n",
       "   review_scores_value  review_scores_location  review_scores_cleanliness  \\\n",
       "0                 10.0                     9.0                       10.0   \n",
       "1                 10.0                    10.0                       10.0   \n",
       "\n",
       "   review_scores_communication  review_scores_rating  \n",
       "0                         10.0                  95.0  \n",
       "1                         10.0                  96.0  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('For the \"mean-feature set\",\\n\\tthe percentage of missing values for each column is shown below\\n', round( \n",
    "    listings[mean_features].isnull().sum(axis = 0)/len(listings), 3))\n",
    "listings[mean_features].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the \"mode-feature set\",\n",
      "\tthe percentage of missing values for each column is shown below\n",
      " bathrooms        0.004\n",
      "bedrooms         0.002\n",
      "beds             0.000\n",
      "property_type    0.000\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>beds</th>\n",
       "      <th>property_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Apartment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Apartment</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   bathrooms  bedrooms  beds property_type\n",
       "0        1.0       1.0   1.0     Apartment\n",
       "1        1.0       1.0   1.0     Apartment"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('For the \"mode-feature set\",\\n\\tthe percentage of missing values for each column is shown below\\n', round( \n",
    "    listings[mode_features].isnull().sum(axis = 0)/len(listings), 3))\n",
    "listings[mode_features].head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Missing value imputation**\n",
    "- Missing values imputations using `\"continuous_imputation()\"` function\n",
    "    - Based on Zacks Shen's analysis, there are 3 types of continous features with missing values, including \"zero_features\" (fill with 0), \"mean_features\"(fill with col-mean) and \"mode_features\"(fill with most-frequent value, can be used for categorical features such as 'property_type')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def continuous_imputation(X_train, X_valid, y_train, y_valid): \n",
    "    \n",
    "    zero_features = ['reviews_per_month', 'host_response_rate', 'host_is_superhost', 'security_deposit', 'cleaning_fee']\n",
    "    mean_features = ['host_acceptance_rate', 'review_scores_accuracy', 'review_scores_checkin', \n",
    "                             'review_scores_value', 'review_scores_location', 'review_scores_cleanliness', \n",
    "                             'review_scores_communication', 'review_scores_rating']\n",
    "    mode_features = ['bathrooms', 'bedrooms', 'beds', 'property_type']\n",
    "\n",
    "    X_train, X_valid, y_train, y_valid = X_train.copy(), X_valid.copy(), y_train.copy(), y_valid.copy()\n",
    "\n",
    "    # Zero imputation\n",
    "    X_train, X_valid = simple_imputer(zero_features, 'constant', X_train, X_valid, 'float')\n",
    "    \n",
    "    # Mean imputation\n",
    "    X_train, X_valid = simple_imputer(mean_features, 'mean', X_train, X_valid, 'float')\n",
    "    \n",
    "    # Mode imputation\n",
    "    X_train, X_valid = simple_imputer(mode_features, 'most_frequent', X_train, X_valid, 'int')\n",
    "    \n",
    "    return X_train, X_valid, y_train, y_valid\n",
    "\n",
    "def simple_imputer(imp_features, strategy, X_train, X_valid, feature_type):\n",
    "    if strategy == 'constant':\n",
    "        imp = SimpleImputer(missing_values=np.nan, strategy='constant', fill_value=0)\n",
    "    else:\n",
    "        imp = SimpleImputer(missing_values=np.nan, strategy=strategy)\n",
    "        \n",
    "    X_train_imp = pd.DataFrame(imp.fit_transform(X_train[imp_features]))\n",
    "    X_valid_imp = pd.DataFrame(imp.transform(X_valid[imp_features]))\n",
    "    X_train_imp.columns = imp_features\n",
    "    X_valid_imp.columns = imp_features\n",
    "\n",
    "    X_train_imp.index = X_train.index\n",
    "    X_valid_imp.index = X_valid.index\n",
    "    \n",
    "    if strategy == 'most_frequent':\n",
    "        X_train_imp[['bathrooms', 'bedrooms', 'beds']] = X_train_imp[['bathrooms', 'bedrooms', 'beds']].astype(feature_type)\n",
    "        X_valid_imp[['bathrooms', 'bedrooms', 'beds']] = X_valid_imp[['bathrooms', 'bedrooms', 'beds']].astype(feature_type)\n",
    "    else: \n",
    "        X_train_imp = X_train_imp.astype( feature_type )\n",
    "        X_valid_imp = X_valid_imp.astype( feature_type )\n",
    "\n",
    "    # Replace the unimputated columns\n",
    "    for feature in imp_features:\n",
    "        X_train.loc[:, feature] = X_train_imp.loc[:, feature]\n",
    "        X_valid.loc[:, feature] = X_valid_imp.loc[:, feature]\n",
    "    \n",
    "    return X_train, X_valid\n",
    "\n",
    "\n",
    "# Split train and valid, an example.\n",
    "\n",
    "# tt = listings.copy()\n",
    "# kfold = 1\n",
    "\n",
    "# X_train = tt[tt.kfold != kfold]\n",
    "# X_valid = tt[tt.kfold == kfold]\n",
    "# y_train = X_train.pop('price')\n",
    "# y_valid = X_valid.pop('price')\n",
    "# X_train, X_valid, y_train, y_valid = continuous_imputation(X_train, X_valid, y_train, y_valid)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Handle categorical variables**:\n",
    "- Encoding categorical variable, \"amenities\" from the listings data using `\"encode_amenities()\"` function\n",
    "- Encoding other categorical variables, using one-hot encoding or target encoding using `\"category_encoding\"` function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Encoding \"amenities\" categorical variable** using \"encode_amenities()\" function\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    {TV,\"Cable TV\",Internet,\"Wireless Internet\",\"A...\n",
      "1    {TV,Internet,\"Wireless Internet\",Kitchen,\"Free...\n",
      "2    {TV,\"Cable TV\",Internet,\"Wireless Internet\",\"A...\n",
      "3    {Internet,\"Wireless Internet\",Kitchen,\"Indoor ...\n",
      "4    {TV,\"Cable TV\",Internet,\"Wireless Internet\",Ki...\n",
      "Name: amenities, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print( listings.amenities.head() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3818, 595)\n",
      "(3818, 634)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>amenity_encod_Breakfast</th>\n",
       "      <th>amenity_encod_Elevator in Building</th>\n",
       "      <th>amenity_encod_Cat(s)</th>\n",
       "      <th>amenity_encod_Dryer</th>\n",
       "      <th>amenity_encod_Essentials</th>\n",
       "      <th>amenity_encod_Internet</th>\n",
       "      <th>amenity_encod_Free Parking on Premises</th>\n",
       "      <th>amenity_encod_Safety Card</th>\n",
       "      <th>amenity_encod_Smoking Allowed</th>\n",
       "      <th>amenity_encod_First Aid Kit</th>\n",
       "      <th>...</th>\n",
       "      <th>amenity_encod_Laptop Friendly Workspace</th>\n",
       "      <th>amenity_encod_Buzzer/Wireless Intercom</th>\n",
       "      <th>amenity_encod_Cable TV</th>\n",
       "      <th>amenity_encod_Air Conditioning</th>\n",
       "      <th>amenity_encod_Carbon Monoxide Detector</th>\n",
       "      <th>amenity_encod_Doorman</th>\n",
       "      <th>amenity_encod_Fire Extinguisher</th>\n",
       "      <th>amenity_encod_Hangers</th>\n",
       "      <th>amenity_encod_Heating</th>\n",
       "      <th>amenity_encod_24-Hour Check-in</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   amenity_encod_Breakfast  amenity_encod_Elevator in Building  \\\n",
       "1                    False                               False   \n",
       "2                    False                               False   \n",
       "3                    False                               False   \n",
       "\n",
       "   amenity_encod_Cat(s)  amenity_encod_Dryer  amenity_encod_Essentials  \\\n",
       "1                 False                 True                      True   \n",
       "2                  True                 True                      True   \n",
       "3                 False                 True                      True   \n",
       "\n",
       "   amenity_encod_Internet  amenity_encod_Free Parking on Premises  \\\n",
       "1                    True                                    True   \n",
       "2                    True                                    True   \n",
       "3                    True                                   False   \n",
       "\n",
       "   amenity_encod_Safety Card  amenity_encod_Smoking Allowed  \\\n",
       "1                       True                          False   \n",
       "2                      False                          False   \n",
       "3                       True                          False   \n",
       "\n",
       "   amenity_encod_First Aid Kit  ...  amenity_encod_Laptop Friendly Workspace  \\\n",
       "1                         True  ...                                    False   \n",
       "2                        False  ...                                    False   \n",
       "3                        False  ...                                    False   \n",
       "\n",
       "   amenity_encod_Buzzer/Wireless Intercom  amenity_encod_Cable TV  \\\n",
       "1                                    True                   False   \n",
       "2                                   False                    True   \n",
       "3                                   False                   False   \n",
       "\n",
       "   amenity_encod_Air Conditioning  amenity_encod_Carbon Monoxide Detector  \\\n",
       "1                           False                                    True   \n",
       "2                            True                                    True   \n",
       "3                           False                                    True   \n",
       "\n",
       "   amenity_encod_Doorman  amenity_encod_Fire Extinguisher  \\\n",
       "1                  False                             True   \n",
       "2                  False                            False   \n",
       "3                  False                             True   \n",
       "\n",
       "   amenity_encod_Hangers  amenity_encod_Heating  \\\n",
       "1                  False                   True   \n",
       "2                  False                   True   \n",
       "3                  False                   True   \n",
       "\n",
       "   amenity_encod_24-Hour Check-in  \n",
       "1                           False  \n",
       "2                           False  \n",
       "3                           False  \n",
       "\n",
       "[3 rows x 40 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def encode_amenities(df):\n",
    "    df.amenities.replace('[{}\"]', \"\", regex=True, inplace=True)\n",
    "    df.amenities = df.amenities.str.split(\",\")\n",
    "    \n",
    "    ## get a unique set of amenities \n",
    "    uniq_amenities = set().union(*df.amenities) \n",
    "    \n",
    "    # remove '', None and \"Washer / Dryer\" (due to low frequency)\n",
    "    uniq_amenities.remove('')\n",
    "#     uniq_amenities.remove(None)\n",
    "    uniq_amenities.remove('Washer / Dryer')\n",
    "    \n",
    "    # encoding amenities\n",
    "    amenities_encod = pd.DataFrame()\n",
    "    for item in uniq_amenities:\n",
    "        amenities_encod[f\"amenity_encod_{item}\"] = df.amenities.str.contains(item, regex=False)\n",
    "    \n",
    "    # Concat encoded amenities and data_frame\n",
    "    df = pd.concat([df, amenities_encod], axis=1)\n",
    "    # remove the \"amenities\" col\n",
    "    df.pop('amenities')  ## then remove \"amenities\" col\n",
    "    \n",
    "    return df\n",
    "\n",
    "print(listings.shape)\n",
    "listings_encode = encode_amenities(listings) ## --- apply \"encode_amenities()\" function\n",
    "print(listings_encode.shape)\n",
    "\n",
    "listings_encode.loc[1:3, listings_encode.columns[ listings_encode.columns.str.contains(\"amenity_encod\") ]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After encoding the \"amenities\" column, we can get 40 more columns, each represents whether the property provides specific amenity such as Breakfast and elevator in building shown above. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Encoding other categorical variables**, using one-hot encoding or target encoding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def _one_hot_encoding(X_train, X_valid, y_train, y_valid):\n",
    "    X_train, X_valid, y_train, y_valid = X_train.copy(), X_valid.copy(), y_train.copy(), y_valid.copy()\n",
    "\n",
    "    oe_enc_features = ['cancellation_policy', 'require_guest_profile_picture', 'require_guest_phone_verification', \n",
    "                           'neighbourhood_group_cleansed', 'property_type', 'instant_bookable', 'room_type', 'bed_type']\n",
    "\n",
    "    oe = OrdinalEncoder()\n",
    "    X_train[oe_enc_features] = oe.fit_transform(X_train[oe_enc_features])\n",
    "    X_valid[oe_enc_features] = oe.transform(X_valid[oe_enc_features])\n",
    "\n",
    "    return X_train, X_valid, y_train, y_valid\n",
    "\n",
    "def _target_encoding(X_train, X_valid, y_train, y_valid):\n",
    "    X_train, X_valid, y_train, y_valid = X_train.copy(), X_valid.copy(), y_train.copy(), y_valid.copy()\n",
    "\n",
    "    target_enc_features = ['cancellation_policy', 'require_guest_profile_picture', 'require_guest_phone_verification', \n",
    "                           'neighbourhood_group_cleansed', 'property_type', 'instant_bookable', 'room_type', 'bed_type']\n",
    "\n",
    "    # Create the encoder instance. Choose m to control noise.\n",
    "    target_enc = MEstimateEncoder(cols=target_enc_features, m=5.0)\n",
    "    X_train = target_enc.fit_transform(X_train, y_train)\n",
    "    X_valid = target_enc.transform(X_valid)\n",
    "\n",
    "    return X_train, X_valid, y_train, y_valid\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Finally, we can construct a function `\"ml_dataprep()\"` for ml_dataprep.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def ml_dataprep(df, features, target, kfold, target_encoding=True):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        df (Pandas DataFrame): \"listings\" data.\n",
    "        features (list): The ML features.\n",
    "        target (str): 'price'\n",
    "        kfold: 1-5\n",
    "        target_encoding: True or False\n",
    "    \"\"\"\n",
    "    import warnings\n",
    "    warnings.filterwarnings(\"ignore\") # ignore target encoding warnings\n",
    "\n",
    "#     features.append(target)\n",
    "#     df = df[features]\n",
    "\n",
    "#     # Encode amenities --- using \"encode_amenities()\" function\n",
    "#     df = encode_amenities(df) \n",
    "\n",
    "    # Split train and valid\n",
    "    X_train = df[df.kfold != kfold]\n",
    "    X_valid = df[df.kfold == kfold]\n",
    "    y_train = X_train.pop(target)\n",
    "    y_valid = X_valid.pop(target) # 'price'\n",
    "\n",
    "    # Imputation                  --- using \"continuous_imputation()\" function\n",
    "    X_train, X_valid, y_train, y_valid = continuous_imputation(X_train, X_valid, y_train, y_valid)\n",
    "\n",
    "    # Target Encoding             --- using \"_target_encoding()\" function\n",
    "    if target_encoding:\n",
    "        X_train, X_valid, y_train, y_valid = _target_encoding(X_train, X_valid, y_train, y_valid)\n",
    "        \n",
    "    else:  # one-hot encoding     --- using \"_one_hot_encoding()\" function\n",
    "        X_train, X_valid, y_train, y_valid = _one_hot_encoding(X_train, X_valid, y_train, y_valid)\n",
    "\n",
    "    return X_train, X_valid, y_train, y_valid\n",
    "\n",
    "\n",
    "# listings = pd.read_csv(\"listings_cs_kfold.csv\")\n",
    "# listings = ETL_pipeline(listings).parse_listings()\n",
    "\n",
    "# base_features = ['host_acceptance_rate', 'neighbourhood_group_cleansed', 'property_type', 'room_type',\n",
    "#             'bathrooms', 'bedrooms', 'beds', 'bed_type', 'number_of_reviews', 'review_scores_rating',\n",
    "#             'review_scores_accuracy', 'review_scores_cleanliness', 'review_scores_checkin', 'review_scores_communication',\n",
    "#             'review_scores_location', 'review_scores_value', 'reviews_per_month', 'host_response_rate', 'host_is_superhost', \n",
    "#             'accommodates', 'security_deposit', 'cleaning_fee', 'guests_included', 'extra_people', 'minimum_nights', \n",
    "#             'maximum_nights', 'instant_bookable', 'cancellation_policy', 'require_guest_profile_picture', \n",
    "#             'require_guest_phone_verification', 'amenities', 'kfold']\n",
    "\n",
    "# kfold = 1\n",
    "\n",
    "# X_train, X_valid, y_train, y_valid = ml_dataprep(df=listings, features=base_features, target='price', \\\n",
    "#                                                  kfold=kfold, target_encoding=True)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (4) Data Modeling and Evaluate the Results\n",
    "- **Two model settings** (Compared two sets of features)\n",
    "    - model 1: m1_features\n",
    "    - model 2: m1_features + convenience_score related features..\n",
    "    \n",
    "- **Two machine learning algorithms**:\n",
    "    - [LinearRegression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html)\n",
    "    - [RandomForests](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html)\n",
    "    \n",
    "- **Evaluation metric**:\n",
    "    - [RMSE](https://en.wikipedia.org/wiki/Root-mean-square_deviation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ML1, kfold: 0. RMSE: 56.70855885709866\n",
      "ML1, kfold: 1. RMSE: 66.50284923910483\n",
      "ML1, kfold: 2. RMSE: 60.81836541597313\n",
      "ML1, kfold: 3. RMSE: 62.798432234822165\n",
      "ML1, kfold: 4. RMSE: 86.31317047062942\n",
      "Model 1 (LinearRegression with target_encoding=False). Average RMSE: 66.62827524352565\n",
      "\n",
      "ML1, kfold: 0. RMSE: 55.47840623642598\n",
      "ML1, kfold: 1. RMSE: 65.2719817746783\n",
      "ML1, kfold: 2. RMSE: 59.29221420761654\n",
      "ML1, kfold: 3. RMSE: 62.10852061619225\n",
      "ML1, kfold: 4. RMSE: 86.9957031795546\n",
      "Model 1 (LinearRegression with target_encoding=True). Average RMSE: 65.82936520289353\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "listings = pd.read_csv(\"listings_cs_kfold.csv\")\n",
    "listings = ETL_pipeline(listings).parse_listings()\n",
    "\n",
    "### input of \"ml_dataprep()\"....\n",
    "m1_features_input = ['host_acceptance_rate', 'neighbourhood_group_cleansed', 'property_type', 'room_type',\n",
    "            'bathrooms', 'bedrooms', 'beds', 'bed_type', 'number_of_reviews', 'review_scores_rating',\n",
    "            'review_scores_accuracy', 'review_scores_cleanliness', 'review_scores_checkin', 'review_scores_communication',\n",
    "            'review_scores_location', 'review_scores_value', 'reviews_per_month', 'host_response_rate', 'host_is_superhost', \n",
    "            'accommodates', 'security_deposit', 'cleaning_fee', 'guests_included', 'extra_people', 'minimum_nights', \n",
    "            'maximum_nights', 'instant_bookable', 'cancellation_policy', 'require_guest_profile_picture', \n",
    "            'require_guest_phone_verification', 'amenities', 'kfold']\n",
    "\n",
    "\n",
    "####################################\n",
    "#####  Model 1-- m1_features..\n",
    "m1_features = m1_features_input.copy()\n",
    "m1_features.remove('amenities')\n",
    "\n",
    "m1_features_input.append('price')\n",
    "df = listings[m1_features_input].copy()\n",
    "# Encode amenities --- using \"encode_amenities()\" function\n",
    "df = encode_amenities(df) \n",
    "    \n",
    "for target_encoding in [False, True]:\n",
    "    \n",
    "    md1_RMSE = []\n",
    "    \n",
    "    for kfold in range(5):\n",
    "\n",
    "        X_train, X_test, y_train, y_test = ml_dataprep( df=df, features=m1_features_input, target='price', \\\n",
    "                                                       kfold=kfold, target_encoding=target_encoding)\n",
    "        ## LinearRegression function\n",
    "        lr_model = LinearRegression()\n",
    "        lr_parameters = { \"fit_intercept\": [True, False]}\n",
    "        lr_grid = GridSearchCV(estimator=lr_model, \n",
    "                            param_grid = lr_parameters, \n",
    "                            cv = 3, \n",
    "                            n_jobs=-1,\n",
    "    #                         random_state=kfold,\n",
    "                            )\n",
    "        lr_grid.fit(X_train[m1_features], y_train)\n",
    "        test_preds = lr_grid.predict(X_test[m1_features])\n",
    "\n",
    "        RMSE = mean_squared_error(y_test, test_preds, squared=False)\n",
    "        print(f\"ML1, kfold: {kfold}. RMSE: {RMSE}\")\n",
    "        md1_RMSE.append(RMSE)\n",
    "    \n",
    "    print(f\"Model 1 (LinearRegression with target_encoding={target_encoding}). Average RMSE: {np.mean(md1_RMSE)}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ML2, kfold: 0. RMSE: 55.31544479857226\n",
      "ML2, kfold: 1. RMSE: 64.44421460776245\n",
      "ML2, kfold: 2. RMSE: 58.77542158192223\n",
      "ML2, kfold: 3. RMSE: 61.59597900497572\n",
      "ML2, kfold: 4. RMSE: 82.6865979719371\n",
      "Model 2 (LinearRegression with target_encoding=False). Average RMSE: 64.56353159303396\n",
      "\n",
      "ML2, kfold: 0. RMSE: 55.279150838411404\n",
      "ML2, kfold: 1. RMSE: 64.29133372829887\n",
      "ML2, kfold: 2. RMSE: 58.872667001227185\n",
      "ML2, kfold: 3. RMSE: 61.67166260732547\n",
      "ML2, kfold: 4. RMSE: 86.02107090313123\n",
      "Model 2 (LinearRegression with target_encoding=True). Average RMSE: 65.22717701567883\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "####################################\n",
    "#####  Model 2-- m2_features..\n",
    "\n",
    "### input of \"ml_dataprep()\"....\n",
    "m1_features_input = ['host_acceptance_rate', 'neighbourhood_group_cleansed', 'property_type', 'room_type',\n",
    "            'bathrooms', 'bedrooms', 'beds', 'bed_type', 'number_of_reviews', 'review_scores_rating',\n",
    "            'review_scores_accuracy', 'review_scores_cleanliness', 'review_scores_checkin', 'review_scores_communication',\n",
    "            'review_scores_location', 'review_scores_value', 'reviews_per_month', 'host_response_rate', 'host_is_superhost', \n",
    "            'accommodates', 'security_deposit', 'cleaning_fee', 'guests_included', 'extra_people', 'minimum_nights', \n",
    "            'maximum_nights', 'instant_bookable', 'cancellation_policy', 'require_guest_profile_picture', \n",
    "            'require_guest_phone_verification', 'amenities', 'kfold']\n",
    "\n",
    "m2_features_input = m1_features_input.copy()\n",
    "m2_features_input.extend([\"cs_attr_5_counts\", \"cs_park_5_counts\", \\\n",
    "                                                   \"cs_attr_10_avgdist\", \"cs_park_10_avgdist\"])\n",
    "\n",
    "m2_features = m2_features_input.copy()\n",
    "m2_features.remove('amenities')\n",
    "\n",
    "\n",
    "m2_features_input.append('price')\n",
    "df = listings[m2_features_input].copy()\n",
    "# Encode amenities --- using \"encode_amenities()\" function\n",
    "df = encode_amenities(df) \n",
    "    \n",
    "for target_encoding in [False, True]:\n",
    "    \n",
    "    md2_RMSE = []\n",
    "    \n",
    "    for kfold in range(5):\n",
    "\n",
    "        X_train, X_test, y_train, y_test = ml_dataprep( df=df, features=m2_features_input, target='price', \\\n",
    "                                                       kfold=kfold, target_encoding=target_encoding)\n",
    "        ## LinearRegression function\n",
    "        lr_model = LinearRegression()\n",
    "        lr_parameters = { \"fit_intercept\": [True, False]}\n",
    "        lr_grid = GridSearchCV(estimator=lr_model, \n",
    "                            param_grid = lr_parameters, \n",
    "                            cv = 3, \n",
    "                            n_jobs=-1,\n",
    "    #                         random_state=kfold,\n",
    "                            )\n",
    "        lr_grid.fit(X_train[m2_features], y_train)\n",
    "        test_preds = lr_grid.predict(X_test[m2_features])\n",
    "\n",
    "        RMSE = mean_squared_error(y_test, test_preds, squared=False)\n",
    "        print(f\"ML2, kfold: {kfold}. RMSE: {RMSE}\")\n",
    "        md2_RMSE.append(RMSE)\n",
    "\n",
    "    print(f\"Model 2 (LinearRegression with target_encoding={target_encoding}). Average RMSE: {np.mean(md2_RMSE)}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using \"Linear Regression model\", we find that:\n",
    "<img src=\"../result/result_LinearReg.png\" width=600 height=420 />\n",
    "\n",
    "- with target_encoding = False (that is, we use `one-hot-encoding`), \n",
    "    - Model 1 with baseline feature obtains Average RMSE: 66.628.\n",
    "    - Model 2 with baseline feature and four convenience_score-related features obtains Average RMSE: 64.564.\n",
    "    \n",
    "    Thus, the four convenience_score-related features I generated help improve price prediction of Airbnb properties, given the fact that we use simple \"one-hot-encoding\" technique for categorical features.\n",
    "    \n",
    "    \n",
    "- with target_encoding = True (that is, we use `target-encoding`), \n",
    "    - Model 1 with baseline feature obtains Average RMSE: 65.829.\n",
    "    - Model 2 with baseline feature and four convenience_score-related features obtains Average RMSE: 65.227.\n",
    "    \n",
    "    Thus, the four convenience_score-related features I generated help improve price prediction of Airbnb properties, given the fact that we use advanced \"target-encoding\" technique for categorical features.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### I also implement \"Random Forests\" algorithm to see if four convenience-score-related features help improve price prediction performance. \n",
    "<img src=\"../result/result_RandomForest.png\" width=500 height=320 />\n",
    "\n",
    "- with target_encoding = False (that is, we use `one-hot-encoding`), \n",
    "    - Model 1 with baseline feature obtains Average RMSE: 56.836.\n",
    "    - Model 2 with baseline feature and four convenience_score-related features obtains Average RMSE:  55.400.\n",
    "    \n",
    "    Thus, the four convenience_score-related features I generated help improve price prediction of Airbnb properties, given the fact that we use simple \"one-hot-encoding\" technique for categorical features.\n",
    "    \n",
    "    \n",
    "- with target_encoding = True (that is, we use `target-encoding`), \n",
    "    - Model 1 with baseline feature obtains Average RMSE: 55.989.\n",
    "    - Model 2 with baseline feature and four convenience_score-related features obtains Average RMSE: 55.269.\n",
    "    \n",
    "    Thus, the four convenience_score-related features I generated help improve price prediction of Airbnb properties, given the fact that we use advanced \"target-encoding\" technique for categorical features.\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  12 out of  12 | elapsed:    1.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  12 out of  12 | elapsed:    1.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ML1, kfold: 0. RMSE: 54.422594651049046\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  12 out of  12 | elapsed:    1.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  12 out of  12 | elapsed:    1.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ML1, kfold: 1. RMSE: 63.100122356555644\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  12 out of  12 | elapsed:    1.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  12 out of  12 | elapsed:    1.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ML1, kfold: 2. RMSE: 57.432182418377955\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  12 out of  12 | elapsed:    1.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  12 out of  12 | elapsed:    1.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ML1, kfold: 3. RMSE: 59.69225249036197\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  12 out of  12 | elapsed:    1.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  12 out of  12 | elapsed:    1.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ML1, kfold: 4. RMSE: 49.532044227493905\n",
      "Model 1 (RandomForest with target_encoding=False). Average RMSE: 56.8358392287677\n",
      "\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  12 out of  12 | elapsed:    1.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  12 out of  12 | elapsed:    1.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ML1, kfold: 0. RMSE: 52.66218590472293\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  12 out of  12 | elapsed:    1.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  12 out of  12 | elapsed:    1.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ML1, kfold: 1. RMSE: 61.86024764124715\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  12 out of  12 | elapsed:    1.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  12 out of  12 | elapsed:    1.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ML1, kfold: 2. RMSE: 56.92278624687547\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  12 out of  12 | elapsed:    1.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  12 out of  12 | elapsed:    1.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ML1, kfold: 3. RMSE: 59.43959069635754\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  12 out of  12 | elapsed:    1.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  12 out of  12 | elapsed:    1.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ML1, kfold: 4. RMSE: 49.06027695692371\n",
      "Model 1 (RandomForest with target_encoding=True). Average RMSE: 55.989017489225354\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "listings = pd.read_csv(\"listings_cs_kfold.csv\")\n",
    "listings = ETL_pipeline(listings).parse_listings()\n",
    "\n",
    "### input of \"ml_dataprep()\"....\n",
    "m1_features_input = ['host_acceptance_rate', 'neighbourhood_group_cleansed', 'property_type', 'room_type',\n",
    "            'bathrooms', 'bedrooms', 'beds', 'bed_type', 'number_of_reviews', 'review_scores_rating',\n",
    "            'review_scores_accuracy', 'review_scores_cleanliness', 'review_scores_checkin', 'review_scores_communication',\n",
    "            'review_scores_location', 'review_scores_value', 'reviews_per_month', 'host_response_rate', 'host_is_superhost', \n",
    "            'accommodates', 'security_deposit', 'cleaning_fee', 'guests_included', 'extra_people', 'minimum_nights', \n",
    "            'maximum_nights', 'instant_bookable', 'cancellation_policy', 'require_guest_profile_picture', \n",
    "            'require_guest_phone_verification', 'amenities', 'kfold']\n",
    "\n",
    "\n",
    "####################################\n",
    "#####  Model 1-- m1_features..\n",
    "m1_features = m1_features_input.copy()\n",
    "m1_features.remove('amenities')\n",
    "\n",
    "m1_features_input.append('price')\n",
    "df = listings[m1_features_input].copy()\n",
    "# Encode amenities --- using \"encode_amenities()\" function\n",
    "df = encode_amenities(df) \n",
    "    \n",
    "for target_encoding in [False, True]:\n",
    "    \n",
    "    md1_RMSE = []\n",
    "    \n",
    "    for kfold in range(5):\n",
    "\n",
    "        X_train, X_test, y_train, y_test = ml_dataprep( df=df, features=m1_features_input, target='price', \\\n",
    "                                                       kfold=kfold, target_encoding=target_encoding)\n",
    "    \n",
    "        ## RandomForest\n",
    "        rf_model = RandomForestRegressor(random_state=kfold)\n",
    "        rf_parameters = {\n",
    "                        'max_depth': [80, 100],\n",
    "                        'max_features': [2, 3],\n",
    "#                         'min_samples_leaf': [3, 4, 5],\n",
    "#                         'min_samples_split': [8, 10, 12],\n",
    "#                         'n_estimators': [100, 200, 300]\n",
    "                        }\n",
    "        rf_grid = GridSearchCV(estimator = rf_model, param_grid = rf_parameters, \n",
    "                                  cv = 3, n_jobs = -1, verbose = 2)\n",
    "        rf_grid.fit(X_train[m1_features], y_train)\n",
    "        test_preds = rf_grid.predict(X_test[m1_features])\n",
    "\n",
    "        RMSE = mean_squared_error(y_test, test_preds, squared=False)\n",
    "        print(f\"ML1, kfold: {kfold}. RMSE: {RMSE}\")\n",
    "        md1_RMSE.append(RMSE)\n",
    "    \n",
    "    print(f\"Model 1 (RandomForest with target_encoding={target_encoding}). Average RMSE: {np.mean(md1_RMSE)}\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  12 out of  12 | elapsed:    1.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  12 out of  12 | elapsed:    1.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ML2, kfold: 0. RMSE: 52.21765947324597\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  12 out of  12 | elapsed:    1.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  12 out of  12 | elapsed:    1.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ML2, kfold: 1. RMSE: 61.71314719661439\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  12 out of  12 | elapsed:    1.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  12 out of  12 | elapsed:    1.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ML2, kfold: 2. RMSE: 56.392582674441485\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  12 out of  12 | elapsed:    1.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  12 out of  12 | elapsed:    1.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ML2, kfold: 3. RMSE: 58.78185250986093\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  12 out of  12 | elapsed:    1.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  12 out of  12 | elapsed:    1.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ML2, kfold: 4. RMSE: 47.894710480440764\n",
      "Model 2 (RandomForest with target_encoding=False). Average RMSE: 55.39999046692071\n",
      "\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  12 out of  12 | elapsed:    1.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  12 out of  12 | elapsed:    1.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ML2, kfold: 0. RMSE: 52.33677863861145\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  12 out of  12 | elapsed:    1.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  12 out of  12 | elapsed:    1.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ML2, kfold: 1. RMSE: 61.11901138984703\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  12 out of  12 | elapsed:    1.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  12 out of  12 | elapsed:    1.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ML2, kfold: 2. RMSE: 56.451680169673054\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  12 out of  12 | elapsed:    1.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  12 out of  12 | elapsed:    1.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ML2, kfold: 3. RMSE: 58.926668218998046\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  12 out of  12 | elapsed:    1.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  12 out of  12 | elapsed:    1.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ML2, kfold: 4. RMSE: 47.51225096308627\n",
      "Model 2 (RandomForest with target_encoding=True). Average RMSE: 55.26927787604317\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "####################################\n",
    "#####  Model 2-- m2_features..\n",
    "\n",
    "### input of \"ml_dataprep()\"....\n",
    "m1_features_input = ['host_acceptance_rate', 'neighbourhood_group_cleansed', 'property_type', 'room_type',\n",
    "            'bathrooms', 'bedrooms', 'beds', 'bed_type', 'number_of_reviews', 'review_scores_rating',\n",
    "            'review_scores_accuracy', 'review_scores_cleanliness', 'review_scores_checkin', 'review_scores_communication',\n",
    "            'review_scores_location', 'review_scores_value', 'reviews_per_month', 'host_response_rate', 'host_is_superhost', \n",
    "            'accommodates', 'security_deposit', 'cleaning_fee', 'guests_included', 'extra_people', 'minimum_nights', \n",
    "            'maximum_nights', 'instant_bookable', 'cancellation_policy', 'require_guest_profile_picture', \n",
    "            'require_guest_phone_verification', 'amenities', 'kfold']\n",
    "\n",
    "m2_features_input = m1_features_input.copy()\n",
    "m2_features_input.extend([\"cs_attr_5_counts\", \"cs_park_5_counts\", \\\n",
    "                                                   \"cs_attr_10_avgdist\", \"cs_park_10_avgdist\"])\n",
    "\n",
    "m2_features = m2_features_input.copy()\n",
    "m2_features.remove('amenities')\n",
    "\n",
    "\n",
    "m2_features_input.append('price')\n",
    "df = listings[m2_features_input].copy()\n",
    "# Encode amenities --- using \"encode_amenities()\" function\n",
    "df = encode_amenities(df) \n",
    "    \n",
    "for target_encoding in [False, True]:\n",
    "    \n",
    "    md2_RMSE = []\n",
    "    \n",
    "    for kfold in range(5):\n",
    "\n",
    "        X_train, X_test, y_train, y_test = ml_dataprep( df=df, features=m2_features_input, target='price', \\\n",
    "                                                       kfold=kfold, target_encoding=target_encoding)\n",
    "        import warnings\n",
    "        warnings.filterwarnings(\"ignore\") \n",
    "    \n",
    "        ## RandomForest\n",
    "        rf_model = RandomForestRegressor(random_state=kfold)\n",
    "        rf_parameters = {\n",
    "                        'max_depth': [80, 100],\n",
    "                        'max_features': [2, 3],\n",
    "#                         'min_samples_leaf': [3, 4, 5],\n",
    "#                         'min_samples_split': [8, 10, 12],\n",
    "#                         'n_estimators': [100, 200, 300]\n",
    "                        }\n",
    "        rf_grid = GridSearchCV(estimator = rf_model, param_grid = rf_parameters, \n",
    "                                  cv = 3, n_jobs = -1, verbose = 2)\n",
    "        rf_grid.fit(X_train[m2_features], y_train)\n",
    "        test_preds = rf_grid.predict(X_test[m2_features])\n",
    "\n",
    "        RMSE = mean_squared_error(y_test, test_preds, squared=False)\n",
    "        print(f\"ML2, kfold: {kfold}. RMSE: {RMSE}\")\n",
    "        md2_RMSE.append(RMSE)\n",
    "\n",
    "    print(f\"Model 2 (RandomForest with target_encoding={target_encoding}). Average RMSE: {np.mean(md2_RMSE)}\\n\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    \n",
    "## Summary,\n",
    "- **both Linear Regression and Random Forests suggest to include four convenience_score-related features (`\"cs_attr_5_counts\", \"cs_park_5_counts\", \"cs_attr_10_avgdist\", \"cs_park_10_avgdist\"`) into the price prediction model for the Settle datasets, which reduce the average RMSE compared to the one without them.**\n",
    "    - Particularly, these four features have more adds-on when we encode categorical variables using simple 'one-hot-encoding' technique.\n",
    "- **it is not surprising that RandomForest outperforms simple linear regression model.**\n",
    "- **if we choose the RandomForests model as our final model, target-encoding for categorical variables outperforms the one-hot encoding.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
